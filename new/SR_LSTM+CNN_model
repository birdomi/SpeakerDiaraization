import numpy as np
import tensorflow as tf
import os 
import os.path
from python_speech_features import mfcc
from python_speech_features import fbank
from python_speech_features import delta
import scipy.io.wavfile as wav
from scipy import signal
import matplotlib.pyplot as plt
import librosa

audiocut_min=int(1*100)#second*100
audiocut_max=int(1*100)#second*100


class Libri(): 
    def makeCompareDataset(self,dataSet,seqLengthSet,SpeakerNo):#it need dataset that returned from method, returnMFCCarray
        spCPx1=[];spCPx1_length=[];spCPx2=[];spCPx2_length=[];spCPy=[]
        S=np.arange(dataSet[SpeakerNo].shape[0])
        np.random.shuffle(S)
        S=S[:10]           
        for i in range(len(dataSet)):
            
            if(i==SpeakerNo):
                label=1
            else:
                label=0
            for j in S:
                a = np.arange(dataSet[i].shape[0])
                np.random.shuffle(a)
                if(label==1 and dataSet[i].shape[0]>100):
                    a=a[:100]
                elif(label==1 and dataSet[i].shape[0]<100):
                    a=a
                else:
                    a=a[:10]

                for k in a:
                    spCPx1.append(dataSet[SpeakerNo][j]);spCPx1_length.append(seqLengthSet[SpeakerNo][j])
                    spCPx2.append(dataSet[i][k]);spCPx2_length.append(seqLengthSet[i][k])
                    spCPy.append(label)
        
        spCPx1=np.reshape(spCPx1,(-1,audiocut_max,39,1));spCPx2=np.reshape(spCPx2,(-1,audiocut_max,39,1))
        spCPx1_length=np.reshape(spCPx1_length,(-1));spCPx2_length=np.reshape(spCPx2_length,(-1))
        spCPy=np.reshape(spCPy,(-1,1))
                
        return spCPx1,spCPx1_length,spCPx2,spCPx2_length,spCPy

    def returnMFCCarray(self,speakerfile_dir):
        mfccArray=[]
        Seq_LengthArray=[]
        speakerFile=os.listdir(speakerfile_dir)
        for sfile in speakerFile:   
            #print(sfile)
            curr_work_dir=speakerfile_dir+'/'+sfile
            #print(os.path.isdir(curr_work_dir))
            if(os.path.isdir(curr_work_dir)):
                waves=[f for f in os.listdir(curr_work_dir) if f.endswith('.wav')]                   
                for wave in waves:
                   wave_dir=curr_work_dir+'/'+wave 
                   sr,audio=wav.read(wave_dir)
                   mfc=mfcc(audio,sr)
                   delta1=delta(mfc,1)
                   delta2=delta(mfc,2)
                   mfc=np.append(mfc,delta1,axis=1)
                   mfc=np.append(mfc,delta2,axis=1)
                   
                   mfc_length=len(mfc)
                   numberofCut=int(mfc_length/audiocut_max)
                   for i in range(numberofCut):
                       audiocut_size=200                    
                       Cut_StartPosition=i*audiocut_max
                       
                       Seq_LengthArray.append(audiocut_size)#append Seq_Length
                       
                       mfc_tmp=mfc[Cut_StartPosition:Cut_StartPosition+audiocut_size]
                       
                       #zeroPad to make seq_length same
                       zeroPadSize=audiocut_max-audiocut_size
                       zeroPad=np.zeros((zeroPadSize,39))
                       #attach zeroPad to mfcc Vector.Shape is changed from (audio_cutsize,39) to (500,39)
                       mfc_tmp=np.append(mfc_tmp,zeroPad,axis=0)
                       mfccArray.append(mfc_tmp) 
        
        mfccArray=np.reshape(mfccArray,(-1,audiocut_max,39,1))
        Seq_LengthArray=np.reshape(Seq_LengthArray,(-1))
        return mfccArray,Seq_LengthArray


    def returnLog_Mel_Spectrogram(self,speakerfile_dir,label):
        mfccArray=[]; labelArray=[]
        speakerFile=os.listdir(speakerfile_dir)
        for sfile in speakerFile:  
            curr_work_dir=speakerfile_dir+'/'+sfile
            if(os.path.isdir(curr_work_dir)):
                waves=[f for f in os.listdir(curr_work_dir) if f.endswith('.wav')]                   
                for wave in waves:
                   wave_dir=curr_work_dir+'/'+wave 
                   audio,sr=librosa.audio.load(wave_dir,sr=16000)
                   spec=librosa.feature.melspectrogram(y=audio,sr=sr,hop_length=160,n_fft=1024)
                   spec=librosa.power_to_db(spec,ref=np.max)
                   spec=spec.T
                   spec_length=len(spec)
                   if(int(spec_length)>250):
                      numberofCut=1
                   else:
                      numberofCut=0
                   for i in range(numberofCut):
                       audiocut_size=100                    
                       Cut_StartPosition=i*audiocut_max                       
                       spec_tmp=spec[50+Cut_StartPosition:50+Cut_StartPosition+audiocut_size]
                       labelArray.append(label)
                       mfccArray.append(spec_tmp) 
        
        mfccArray=np.reshape(mfccArray,(-1,audiocut_size,128,1))
        train=mfccArray[:int(len(mfccArray)*0.8)];test=mfccArray[int(len(mfccArray)*0.8):]
        labelArray=np.reshape(labelArray,(-1,1))
        trainLabel=labelArray[:int(len(mfccArray)*0.8)];testLabel=labelArray[int(len(mfccArray)*0.8):]
        return train,test,trainLabel,testLabel

    def makeSpecDataset(self,dataSet,seqLengthSet,SpeakerNo,Start=0):#it need dataset that returned from method, returnSpectrogramarray
        spCPx1=[];spCPx1_length=[];spCPx2=[];spCPx2_length=[];spCPy=[]
        S=np.arange(dataSet[SpeakerNo].shape[0])
        np.random.shuffle(S)
        S=S[:10]           
        for i in range(Start,Start+len(dataSet)):
            
            if(i==SpeakerNo):
                label=1
            else:
                label=0
            for j in S:
                a = np.arange(dataSet[i].shape[0])
                np.random.shuffle(a)
                if(label==1 and dataSet[i].shape[0]>30):
                    a=a[:30]
                elif(label==1 and dataSet[i].shape[0]<30):
                    a=a
                else:
                    a=a[:3]

                for k in a:
                    spCPx1.append(dataSet[SpeakerNo][j]);spCPx1_length.append(seqLengthSet[SpeakerNo][j])
                    spCPx2.append(dataSet[i][k]);spCPx2_length.append(seqLengthSet[i][k])
                    spCPy.append(label)
        
        spCPx1=np.reshape(spCPx1,(-1,audiocut_max,128,1));spCPx2=np.reshape(spCPx2,(-1,audiocut_max,128,1))
        spCPx1_length=np.reshape(spCPx1_length,(-1));spCPx2_length=np.reshape(spCPx2_length,(-1))
        spCPy=np.reshape(spCPy,(-1,1))
                
        return spCPx1,spCPx1_length,spCPx2,spCPx2_length,spCPy

    def returnSmileArray(self,speakerfile_dir):
        mfccArray=[]
        speakerFile=os.listdir(speakerfile_dir)
        for sfile in speakerFile:   
            #print(sfile)
            curr_work_dir=speakerfile_dir+'/'+sfile
            #print(os.path.isdir(curr_work_dir))
            if(os.path.isdir(curr_work_dir)):
                waves=[f for f in os.listdir(curr_work_dir) if f.endswith('.wav')]                   
                for wave in waves:
                   wave_dir=curr_work_dir+'/'+wave 
                   
                   mfc_tmp=self.openSmile.Get_features(wave_dir)
                   mfccArray.append(mfc_tmp) 
        
        mfccArray=np.reshape(mfccArray,(-1,384))
        print(mfccArray.shape)
        return mfccArray

    def makeSmileDataset(self,dataSet,SpeakerNo,Start=0):#it need dataset that returned from method, returnSpectrogramarray
        spCPx1=[];spCPx2=[];spCPy=[]
        S=np.arange(dataSet[SpeakerNo].shape[0])
        np.random.shuffle(S)
        S=S[:10]           
        for i in range(Start,Start+len(dataSet)):
            
            if(i==SpeakerNo):
                label=1
            else:
                label=0
            for j in S:
                a = np.arange(dataSet[i].shape[0])
                np.random.shuffle(a)
                if(label==1 and dataSet[i].shape[0]>30):
                    a=a[:30]
                elif(label==1 and dataSet[i].shape[0]<30):
                    a=a
                else:
                    a=a[:3]

                for k in a:
                    spCPx1.append(dataSet[SpeakerNo][j])
                    spCPx2.append(dataSet[i][k])
                    spCPy.append(label)
        
        spCPx1=np.reshape(spCPx1,(-1,384));spCPx2=np.reshape(spCPx2,(-1,384))
        spCPy=np.reshape(spCPy,(-1,1))
                
        return spCPx1,spCPx2,spCPy
    


class BILSTM_CNN_SR():
    def __init__(self,sess,name,learning_rate,speakerNo):
        self.sess=sess
        self.name=name
        self.learning_rate=learning_rate
        self.speakerNo=speakerNo
        self._build_net()

    def _build_net(self):
        LSTM1=128
        LSTM2=128
        FC1=2048
        FC_Out=self.speakerNo

        self.X=tf.placeholder(tf.float32,[None,audiocut_max,128,1])
        self.Y=tf.placeholder(tf.int64,[None,1])
        
        self.keep_prob=tf.placeholder(tf.float32)  

        self.X1=tf.reshape(self.X,[-1,audiocut_max,128])
        self.RNN1_cell=tf.contrib.rnn.LSTMCell(LSTM1)
        self.RNN2_cell=tf.contrib.rnn.LSTMCell(LSTM2)

        self.cell_fw=tf.contrib.rnn.MultiRNNCell([self.RNN1_cell,self.RNN2_cell])
        self.cell_bw=tf.contrib.rnn.MultiRNNCell([self.RNN1_cell,self.RNN2_cell])

        self.RNN_output,_=tf.nn.bidirectional_dynamic_rnn(self.cell_fw,self.cell_bw,self.X1,dtype=tf.float32)
        self.rnn_output=tf.concat(self.RNN_output,2)
        self.rnn_output=tf.reshape(self.rnn_output,(-1,audiocut_max,LSTM2*2,1))
        
        self.L1 = tf.layers.conv2d(inputs=self.X, filters=16, kernel_size=5,padding='valid',activation=tf.nn.elu,kernel_initializer=tf.contrib.layers.xavier_initializer())            
        self.L2 = tf.layers.conv2d(inputs=self.L1, filters=16, kernel_size=5,padding='valid',activation=tf.nn.elu,kernel_initializer=tf.contrib.layers.xavier_initializer())
        self.L2 = tf.layers.max_pooling2d(self.L2,2,2) 

        self.L3 = tf.layers.conv2d(inputs=self.L2, filters=64, kernel_size=32,padding='same',activation=tf.nn.elu,kernel_initializer=tf.contrib.layers.xavier_initializer())
        self.L4 = tf.layers.conv2d(inputs=self.L3, filters=64, kernel_size=32,padding='same',activation=tf.nn.elu,kernel_initializer=tf.contrib.layers.xavier_initializer())
        self.L4 = tf.layers.max_pooling2d(self.L4,2,2)             
        
        self.Conv1_Out=tf.layers.flatten(self.L4)
        
        self.FC=tf.layers.dense(self.Conv1_Out,FC1,activation=tf.nn.relu)
        self.FC=tf.layers.dropout(self.FC,self.keep_prob)
        self.FC_out=tf.layers.dense(self.FC,FC_Out)

        self.cost=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=self.FC_out,labels=tf.one_hot(self.Y,FC_Out)))
        self.optimizer=tf.train.AdamOptimizer(learning_rate=self.learning_rate).minimize(self.cost)

        self.output=tf.argmax(self.FC_out,1)
        self.accuracy=tf.reduce_mean(tf.cast(tf.equal(self.output,self.Y),tf.float32))

    def printConv(self,x,keep_prob=1.0):
        return self.sess.run([self.L1,self.L2,self.L3,self.L4],feed_dict={self.X:x,self.keep_prob:keep_prob})
            
    def Outputs(self,x,keep_prob=1.0):
        return self.sess.run(self.output,feed_dict={self.X:x,self.keep_prob:keep_prob})

    def Cost(self,x,y,keep_prob=1.0):
        return self.sess.run(self.cost,feed_dict={self.X:x,self.Y:y,self.keep_prob:keep_prob})

    def Train(self,x,y,keep_prob=0.2):
        return self.sess.run(self.optimizer,feed_dict={self.X:x,self.Y:y,self.keep_prob:keep_prob})

    def Accuracy(self,x,y,keep_prob=1.0):
        return self.sess.run(self.accuracy, feed_dict={self.X:x,self.Y:y,self.keep_prob:keep_prob})

    def Feature(self,x,keep_prob=1.0):
        return self.sess.run(self.FC,feed_dict={self.X:x,self.keep_prob:keep_prob})

    def Save(self,name):

        saver=tf.train.Saver()
        saver.save(self.sess, name)

    def Restore(self,name):
        saver=tf.train.Saver()
        saver.restore(self.sess,name)

class Comparer():
    def __init__(self,sess,name,learning_rate):
        self.sess=sess
        self.name=name
        self.learning_rate=learning_rate
        self._build_net()

    def _build_net(self):
        FC1=2048
        FC2=1024
        FC3=512
        FC4=256        
        FC_Out=1

        self.X1=tf.placeholder(tf.float32,[None,2048])
        self.X2=tf.placeholder(tf.float32,[None,2048])
        self.Y=tf.placeholder(tf.int64,[None,1])        
        self.keep_prob=tf.placeholder(tf.float32)  

        self.Input=tf.concat([self.X1,self.X2],axis=1)       
        self.FC1=tf.layers.dense(self.Input,FC1,activation=tf.nn.relu)
        self.FC1=tf.layers.dropout(self.FC,self.keep_prob)
        self.FC2=tf.layers.dense(self.FC1,FC2,activation=tf.nn.relu)
        self.FC2=tf.layers.dropout(self.FC,self.keep_prob)
        self.FC3=tf.layers.dense(self.FC2,FC3,activation=tf.nn.relu)
        self.FC3=tf.layers.dropout(self.FC,self.keep_prob)
        self.FC4=tf.layers.dense(self.FC3,FC4,activation=tf.nn.relu)
        self.FC4=tf.layers.dropout(self.FC,self.keep_prob)
        self.FC_out=tf.layers.dense(self.FC4,FC_Out)

        self.cost=tf.reduce_mean(tf.nn.weighted_cross_entropy_with_logits(logits=self.FC_out,targets=self.Y,pos_weight=1.05))
        self.optimizer=tf.train.AdamOptimizer(learning_rate=self.learning_rate).minimize(self.cost)

        self.output=tf.to_int32(self.FC_out > 0.5)

    def Outputs(self,x,keep_prob=1.0):
        return self.sess.run(self.output,feed_dict={self.X:x,self.keep_prob:keep_prob})

    def Cost(self,x,y,keep_prob=1.0):
        return self.sess.run(self.cost,feed_dict={self.X:x,self.Y:y,self.keep_prob:keep_prob})

    def Train(self,x,y,keep_prob=0.3):
        return self.sess.run(self.optimizer,feed_dict={self.X:x,self.Y:y,self.keep_prob:keep_prob})

    def Accuracy(self,x,y,keep_prob=1.0):
        return self.sess.run(self.accuracy, feed_dict={self.X:x,self.Y:y,self.keep_prob:keep_prob})
    
    def Save(self,name):
        saver=tf.train.Saver()
        saver.save(self.sess, name)

    def Restore(self,name):
        saver=tf.train.Saver()
        saver.restore(self.sess,name)
